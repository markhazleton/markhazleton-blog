extends ../layouts/modern-layout

block layout-content
  br

  section.bg-gradient-primary.py-5
    .container
      .row.align-items-center
        .col-lg-10.mx-auto.text-center
          h1.display-4.fw-bold.mb-3
            i.bi.bi-graph-up-arrow.me-3
            | Engineering Metrics: Git Spark Story
          h2.h3.mb-4 Why Git History Tells the Wrong Story About Developer Productivity
          p.lead.mb-5.
            After discovering how invisible AI contributions vanish in traditional metrics, I encountered
            another measurement trap: using Git history to evaluate team performance.
            The promise of objective data led me down a path of misleading conclusions
            until I discovered what Git analytics actually reveal‚Äîand what they dangerously obscure.

          // Article Metadata
          .mb-4.d-flex.justify-content-center.align-items-center.gap-4
            span
              i.bi.bi-person.me-1
              | Mark Hazleton
            span
              i.bi.bi-calendar.me-1
              | October 2025
            span
              i.bi.bi-tag.me-1
              | Engineering Metrics, Git Analytics, Team Performance

  // Main Article Content
  article#main-article
    .container
      .row
        .col-lg-9.mx-auto
          // Article Content Section
          section#article-content.mb-5

            // Opening Story
            h2.h3.mb-3.text-primary.d-flex.align-items-center
              i.bi.bi-lightning-charge.me-2
              | When "Objective Data" Leads You Astray

            p.lead.mb-4.
              Fresh off struggling to measure AI's contribution to code,
              I thought I'd found the answer to developer productivity measurement:
              Git history. It seemed perfect‚Äîobjective, comprehensive, and already being tracked.
              Every commit, every change, every contributor permanently recorded.
              What could possibly go wrong?

            p.mb-4.
              Everything, as it turns out. Within weeks of implementing Git-based metrics,
              I watched a high-performing team start gaming the system in ways that would have been
              comical if they weren't so damaging. Developers began splitting logical changes into
              multiple commits to boost their numbers. Others started making trivial formatting
              changes to files they'd never touched before to show "broad contribution."
              The most senior engineer‚Äîour best architect‚Äîsuddenly looked like the least productive
              because he spent his time in design documents and code reviews, neither of which
              show up in Git history.

            p.mb-4.
              This is when I discovered Git Spark and, more importantly, began to understand
              the fundamental measurement trap that Git history represents. The problem isn't
              that Git data is wrong‚Äîit's that we're asking it questions it was never designed
              to answer. Git tells us what changed and when, but it's silent on the why, the how,
              and most critically, the impact.

            p.mb-4.
              This article is my journey from treating Git history as gospel truth to understanding
              its severe limitations, and ultimately discovering what it actually can tell us
              when we ask better questions. If you're using commit counts or lines of code
              to measure productivity, you're not just getting incomplete data‚Äîyou're actively
              damaging your team culture while convincing yourself you're being objective.

            // Table of Contents
            nav#table-of-contents.mb-5(aria-label='Table of Contents')
              .card.bg-light
                .card-header
                  h3.card-title.mb-0.fw-bold
                    i.bi.bi-list-ul.me-2
                    | Table of Contents
                .card-body
                  ul.list-group.list-group-flush
                    li.list-group-item: a.text-decoration-none(href='#anti-metrics') The Dangerous Allure of Anti-Metrics
                    li.list-group-item: a.text-decoration-none(href='#missing-data') What Git History Can't Tell You
                    li.list-group-item: a.text-decoration-none(href='#activity-index') From Health Scores to Honest Metrics
                    li.list-group-item: a.text-decoration-none(href='#social-structure') Code as a Window Into Team Dynamics
                    li.list-group-item: a.text-decoration-none(href='#git-spark') What Git Spark Gets Right
                    li.list-group-item: a.text-decoration-none(href='#try-git-spark') Try Git Spark: My First npm Package
                    li.list-group-item: a.text-decoration-none(href='#conclusion') Conclusion: From Simple Answers to Better Questions

          section#git-spark.mb-5
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-stars.me-2
              | What Git Spark Gets Right: Transparency Over Evaluation

            p.lead.mb-4.
              After struggling with misleading metrics and opaque "health scores,"
              I discovered Git Spark‚Äîand realized that its real value wasn't in what
              it measured, but in what it refused to pretend to measure.

            p.mb-4.
              Most Git analytics tools suffer from the same problem: they want to tell you
              whether your team is "good" or "bad," "productive" or "unproductive,"
              "healthy" or "unhealthy." They take limited data and extrapolate sweeping
              judgments. Git Spark does something radical: it admits what it doesn't know.

            .card.mb-4
              .card-header.bg-success.text-white
                h3.card-title.mb-0.fw-bold
                  i.bi.bi-shield-check.me-2
                  | The Git Spark Differentiator: Honest Reporting
              .card-body
                .row.g-4
                  .col-md-6
                    h4.h5.mb-3 What Git Spark Reports
                    ul.mb-0
                      li.mb-2 Observable patterns in commit history
                      li.mb-2 File change frequency and coupling
                      li.mb-2 Author contribution distributions
                      li.mb-2 Temporal patterns in development activity
                      li.mb-2 Code structure evolution over time

                  .col-md-6
                    h4.h5.mb-3 What Git Spark Refuses to Infer
                    ul.mb-0
                      li.mb-2 Developer "productivity" scores
                      li.mb-2 Repository "health" ratings
                      li.mb-2 Code quality judgments
                      li.mb-2 Team performance evaluations
                      li.mb-2 Anything not directly observable in Git

            p.mb-4.
              This honesty is transformative. Instead of generating a dashboard that claims
              your repository has an 87% health score (what does that even mean?), Git Spark
              shows you that:

            ul.mb-4
              li.mb-2 42% of commits touch the authentication module
              li.mb-2 3 developers account for 80% of changes to critical infrastructure
              li.mb-2 Files X and Y change together in 95% of commits
              li.mb-2 Commit frequency dropped 40% in the last quarter

            p.mb-4.
              These are facts. What they mean depends on your context. Maybe the authentication
              churn is expected because you're actively improving security. Maybe the concentrated
              ownership reflects deep expertise, not a problem. Git Spark gives you the data;
              you provide the interpretation.

            .alert.alert-info
              strong.d-block.mb-2
                i.bi.bi-lightbulb.me-2
                | The Real Innovation
              p.mb-0.
                Git Spark's innovation isn't technical‚Äîit's philosophical. By refusing to
                judge what it measures, it preserves the context and nuance that make the
                data actionable. It treats engineering leaders as intelligent adults who
                can interpret patterns, rather than children who need to be told whether
                their repository is "good" or "bad."

            pre.language-javascript
              code.language-javascript.
                // ‚ùå What other tools do
                console.log(`Repository health: Excellent! üéâ`);
                // Meaningless evaluation

                // ‚úÖ What Git Spark does
                console.warn("Deployment status not available from Git history");
                console.log("Observable patterns:", {
                  commitFrequency: data.frequency,
                  coupling: data.fileCoupling,
                  distribution: data.authorDistribution
                });
                // Honest reporting with clear limitations

          section#anti-metrics.mb-5
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-exclamation-triangle.me-2
              | The Dangerous Allure of Anti-Metrics

            p.lead.mb-4.
              The most popular Git-based metrics aren't just unhelpful‚Äîthey're actively harmful.
              I call them "anti-metrics" because they measure motion instead of progress
              and incentivize behaviors that damage both code quality and team culture.

            .card.mb-4
              .card-header.bg-danger.text-white
                h3.card-title.mb-0.fw-bold
                  i.bi.bi-x-circle.me-2
                  | The Three Deadly Anti-Metrics
              .card-body
                .row.g-4
                  .col-md-4
                    .card.h-100.border-danger
                      .card-body
                        h4.card-title.h5
                          i.bi.bi-git.me-2
                          | Commit Count
                        p.card-text.
                          Rewards developers who split logical changes into artificially small commits.
                          Punishes those who make well-structured, comprehensive changes.
                        .alert.alert-danger.mb-0
                          small.
                            <strong>Result:</strong> Noisy history, meaningless granularity,
                            and developers optimizing for metrics instead of quality.

                  .col-md-4
                    .card.h-100.border-danger
                      .card-body
                        h4.card-title.h5
                          i.bi.bi-code-slash.me-2
                          | Lines of Code
                        p.card-text.
                          Measures verbosity, not value. Punishes refactoring and simplification.
                          Rewards copy-paste programming and bloated implementations.
                        .alert.alert-danger.mb-0
                          small.
                            <strong>Result:</strong> Growing codebases that become harder to maintain,
                            with developers afraid to delete unnecessary code.

                  .col-md-4
                    .card.h-100.border-danger
                      .card-body
                        h4.card-title.h5
                          i.bi.bi-clock.me-2
                          | Weekend Commits
                        p.card-text.
                          Often interpreted as "dedication" when it actually signals burnout,
                          poor work-life balance, or unrealistic deadlines.
                        .alert.alert-danger.mb-0
                          small.
                            <strong>Result:</strong> Normalized overwork, exhausted team members,
                            and the false impression that productivity requires sacrifice.

            p.mb-4.
              I learned this lesson the hard way. Within a month of introducing commit-based metrics,
              our most disciplined engineer‚Äîsomeone who routinely made comprehensive, well-tested commits‚Äî
              appeared to be our least productive. Meanwhile, a junior developer who committed after
              every minor change topped the charts. The metrics were giving us exactly the wrong signal.

            pre.language-javascript
              code.language-javascript.
                // üö´ The anti-metric trap
                const productivityScore = {
                  commits: developer.commits.length,          // Meaningless
                  linesAdded: developer.additions,            // Worse than meaningless
                  weekendWork: developer.weekendCommits       // Actively harmful
                };
                // This measures motion, not progress

          section#missing-data.mb-5
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-eye-slash.me-2
              | What Git History Can't Tell You

            p.lead.mb-4.
              The second revelation came when I realized that Git history's real problem
              isn't what it tells us‚Äîit's what it leaves out. The most valuable aspects
              of software development leave no trace in commit logs.

            p.mb-4.
              Remember my previous article on measuring AI contribution? We struggled because
              the AI assistance was invisible in Git history. But that's just one example of a
              much broader problem: Git captures the what and when, but misses almost everything
              that matters for understanding how work actually gets done.

            .row.g-4.mb-4
              .col-md-6
                .card.h-100
                  .card-header.bg-info.text-white
                    h4.card-title.mb-0.h5
                      i.bi.bi-search.me-2
                      | What Git Records
                  .card-body
                    ul.list-unstyled
                      li.mb-2
                        i.bi.bi-check-circle-fill.text-success.me-2
                        | Files changed
                      li.mb-2
                        i.bi.bi-check-circle-fill.text-success.me-2
                        | Lines added/removed
                      li.mb-2
                        i.bi.bi-check-circle-fill.text-success.me-2
                        | Timestamp of changes
                      li.mb-2
                        i.bi.bi-check-circle-fill.text-success.me-2
                        | Commit author
                      li.mb-2
                        i.bi.bi-check-circle-fill.text-success.me-2
                        | Commit message

              .col-md-6
                .card.h-100
                  .card-header.bg-warning.text-dark
                    h4.card-title.mb-0.h5
                      i.bi.bi-question-circle.me-2
                      | What Git Misses
                  .card-body
                    ul.list-unstyled
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Code review quality and outcomes
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Pull request discussion context
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Design decisions and trade-offs
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Testing effort and coverage
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Deployment success and rollbacks
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Pair programming sessions
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Mentoring and knowledge transfer
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | AI assistance level
                      li.mb-2
                        i.bi.bi-x-circle-fill.text-danger.me-2
                        | Business impact of changes

            p.mb-4.
              This hit home when I analyzed our senior architect's contribution. Git showed
              him touching relatively few files with modest line counts. What Git couldn't show:
              he'd spent three weeks preventing a disastrous architectural decision, reviewed
              every critical pull request with detailed feedback, and mentored two junior
              developers through complex implementations. By Git metrics, he looked
              unproductive. In reality, he was our most valuable contributor.

            pre.language-javascript
              code.language-javascript.
                // What Git sees
                const gitView = {
                  commits: 12,
                  filesChanged: 8,
                  linesAdded: 234
                };

                // What Git misses (the actual value)
                const realityView = {
                  architecturalReviews: 15,
                  designDocuments: 3,
                  mentoringHours: 20,
                  productionIncidentsPrevented: 2,
                  technicalDebtReduced: "significant",
                  teamKnowledgeIncreased: "immeasurable"
                };
                // Git metrics miss most of what matters

          section#activity-index.mb-5
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-bar-chart-line.me-2
              | From Health Scores to Honest Metrics

            p.lead.mb-4.
              Here's where I started to understand what Git analytics could legitimately provide.
              The problem wasn't using Git data‚Äîit was pretending it measured things it didn't.
              "Repository health" is marketing speak. "Activity patterns" is honest reporting.

            p.mb-4.
              Many tools generate "health scores" or "productivity ratings" that sound authoritative
              but are fundamentally subjective. They take the limited data Git provides, apply
              arbitrary weights and thresholds, then package it as objective truth. It's
              pseudoscience wrapped in dashboards.

            .card.mb-4
              .card-header.bg-success.text-white
                h3.card-title.mb-0.fw-bold
                  i.bi.bi-check-circle.me-2
                  | Activity Index: What We Can Honestly Measure
              .card-body
                p.mb-3.
                  Instead of fake health scores, we can measure observable activity patterns
                  and let humans interpret what they mean in context:

                dl.mb-0
                  dt.fw-bold.mb-2 Commit Frequency (Normalized)
                  dd.mb-3.
                    How often commits happen, adjusted for team size and project phase.
                    Signals whether development is active, stalled, or sporadic.
                    <span class="text-muted">This is a fact, not a judgment.</span>

                  dt.fw-bold.mb-2 Author Participation Breadth
                  dd.mb-3.
                    How many team members contribute relative to total volume.
                    Reveals whether work is distributed or concentrated.
                    <span class="text-muted">Shows patterns, doesn't evaluate them.</span>

                  dt.fw-bold.mb-2 Change Size Variability
                  dd.mb-3.
                    Coefficient of variation in commit sizes over time.
                    Indicates consistency in development rhythm and working style.
                    <span class="text-muted">Context determines if this is good or bad.</span>

                  dt.fw-bold.mb-2 File Touch Patterns
                  dd.mb-3.
                    Which files change together frequently and who works on them.
                    Exposes coupling, specialization, and potential bottlenecks.
                    <span class="text-muted">Information, not evaluation.</span>

            pre.language-javascript
              code.language-javascript.
                // ‚ùå Fake health score (subjective, misleading)
                const healthScore = calculateMagicFormula(commits, loc, authors);
                // Pretends to know what "healthy" means

                // ‚úÖ Activity index (objective, honest)
                const activityIndex = {
                  frequency: {
                    commitsPerWeek: 47,
                    trend: "stable",
                    normalized: 0.85
                  },
                  breadth: {
                    activeContributors: 8,
                    participationRatio: 0.67,
                    concentration: "moderate"
                  },
                  variance: {
                    commitSizeCV: 1.2,
                    pattern: "consistent",
                    outliers: 3
                  }
                };
                // Reports facts, lets humans interpret

            p.mb-4.
              This shift from evaluation to observation is crucial. We're not saying the team
              is productive or unproductive. We're saying "here are the patterns we observe;
              you decide what they mean for your context." That honesty is what makes
              the data actually useful.

          section#social-structure.mb-5
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-diagram-3.me-2
              | Code as a Window Into Team Dynamics

            p.lead.mb-4.
              This is where Git analytics gets genuinely interesting: not for measuring
              individual productivity, but for revealing socio-technical patterns that
              would otherwise remain invisible. Your code structure mirrors your team
              structure, and Git history exposes that relationship.

            p.mb-4.
              Conway's Law states that organizations build systems that mirror their
              communication structure. Git analytics makes this visible through patterns
              that emerge from how developers interact with the codebase. These patterns
              don't tell you if your team is "good" or "bad"‚Äîthey tell you how your team
              actually works, which is far more valuable.

            .row.g-4.mb-4
              .col-md-6
                .card.h-100.border-primary
                  .card-body
                    h4.card-title.h5
                      i.bi.bi-file-earmark-code.me-2
                      | File Specialization Index (FSI)
                    p.card-text.
                      Measures how concentrated code ownership is across files.
                      High FSI means few people touch each file; low FSI means
                      broad collaboration.

                    .alert.alert-info.mb-3
                      small.fw-bold What It Reveals:
                      ul.mb-0.mt-2
                        li Potential knowledge bottlenecks
                        li Areas of deep expertise vs. shared ownership
                        li Bus factor risks

                    pre.language-python
                      code.language-python.
                        # Calculate FSI per file
                        fsi = 1 / len(unique_authors_per_file)

                        # High FSI (0.8+): Specialist ownership
                        # Low FSI (0.3-): Collaborative ownership

              .col-md-6
                .card.h-100.border-primary
                  .card-body
                    h4.card-title.h5
                      i.bi.bi-shuffle.me-2
                      | Ownership Entropy
                    p.card-text.
                      Measures how evenly contributions are distributed across
                      authors. High entropy means balanced collaboration; low entropy
                      means concentrated ownership.

                    .alert.alert-info.mb-3
                      small.fw-bold What It Reveals:
                      ul.mb-0.mt-2
                        li Whether "collaboration" is real or superficial
                        li Dominant contributors vs. peripheral participants
                        li Team knowledge distribution patterns

                    pre.language-python
                      code.language-python.
                        # Calculate entropy of contributions
                        from math import log
                        entropy = -sum(p * log(p)
                          for p in commit_shares)

                        # High entropy: Balanced team
                        # Low entropy: Concentrated ownership

            .card.mb-4
              .card-header.bg-primary.text-white
                h4.card-title.mb-0.h5
                  i.bi.bi-link-45deg.me-2
                  | Co-Change Coupling: The Hidden Dependencies
              .card-body
                p.mb-3.
                  Files that change together frequently reveal architectural coupling
                  that may not be obvious from static code analysis. This is particularly
                  valuable for identifying:

                .row.g-3
                  .col-md-4
                    .alert.alert-warning.mb-0
                      strong.d-block.mb-2 Architecture Friction
                      small.
                        Files that shouldn't be coupled but always change together
                        signal architectural problems or missing abstractions.

                  .col-md-4
                    .alert.alert-warning.mb-0
                      strong.d-block.mb-2 Hidden Dependencies
                      small.
                        Coupling between seemingly unrelated modules reveals
                        technical debt and refactoring opportunities.

                  .col-md-4
                    .alert.alert-warning.mb-0
                      strong.d-block.mb-2 Team Coordination Needs
                      small.
                        Frequently co-changed files require coordination between
                        their maintainers, indicating collaboration requirements.

            p.mb-4.
              I discovered this accidentally when analyzing why certain features always
              took longer than estimated. Git analytics revealed that three supposedly
              independent modules had high co-change coupling‚Äîthey couldn't be modified
              independently in practice, even though the architecture said they could.
              This explained why every "simple" change rippled through the system.
              The problem wasn't developer skill; it was architectural coupling that
              our planning hadn't accounted for.

          section#try-git-spark.mb-5.bg-light.p-4.rounded-3
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-rocket-takeoff.me-2
              | Try Git Spark: My First npm Package! üéâ

            .row.align-items-center.mb-4
              .col-lg-8
                p.lead.mb-3.
                  Inspired by the principles discussed in this article, I've created and published
                  my first npm package: <strong>git-spark</strong> ‚Äî an honest Git analytics tool
                  that respects what Git history can and cannot tell us.

                p.mb-3.
                  Unlike tools that pretend to know your team's "health score," git-spark provides
                  transparent, actionable insights into repository activity patterns without the
                  misleading judgments.

              .col-lg-4
                .card.border-primary.shadow-sm
                  .card-body.text-center
                    i.bi.bi-box-seam.display-4.text-primary.mb-3
                    h5.card-title npm install git-spark
                    p.text-muted.small My first published package!

            .card.mb-4.border-success
              .card-header.bg-success.text-white
                h4.card-title.mb-0
                  i.bi.bi-star-fill.me-2
                  | What Makes git-spark Different

              .card-body
                .row.g-4
                  .col-md-6
                    h5.h6.fw-bold.mb-3
                      i.bi.bi-check-circle.text-success.me-2
                      | What It Does
                    ul.list-unstyled.mb-0
                      li.mb-2
                        i.bi.bi-arrow-right-circle.text-primary.me-2
                        | Analyzes commit patterns and frequency
                      li.mb-2
                        i.bi.bi-arrow-right-circle.text-primary.me-2
                        | Identifies file coupling and change patterns
                      li.mb-2
                        i.bi.bi-arrow-right-circle.text-primary.me-2
                        | Maps author contribution distributions
                      li.mb-2
                        i.bi.bi-arrow-right-circle.text-primary.me-2
                        | Reveals temporal development trends
                      li.mb-2
                        i.bi.bi-arrow-right-circle.text-primary.me-2
                        | Exports data for custom analysis

                  .col-md-6
                    h5.h6.fw-bold.mb-3
                      i.bi.bi-shield-check.text-success.me-2
                      | What It Doesn't Do
                    ul.list-unstyled.mb-0
                      li.mb-2
                        i.bi.bi-x-circle.text-danger.me-2
                        | Generate fake "health scores"
                      li.mb-2
                        i.bi.bi-x-circle.text-danger.me-2
                        | Make productivity judgments
                      li.mb-2
                        i.bi.bi-x-circle.text-danger.me-2
                        | Rank or compare developers
                      li.mb-2
                        i.bi.bi-x-circle.text-danger.me-2
                        | Pretend to measure code quality
                      li.mb-2
                        i.bi.bi-x-circle.text-danger.me-2
                        | Infer what Git can't tell us

            .card.mb-4.bg-gradient-primary.text-white
              .card-body
                h4.card-title.mb-3
                  i.bi.bi-lightning-charge-fill.me-2
                  | Quick Start

                pre.bg-dark.text-light.p-3.rounded.mb-3
                  code.
                    # Install globally
                    npm install -g git-spark

                    # Or use with npx (no install needed)
                    npx git-spark analyze

                    # Analyze any Git repository
                    cd your-project
                    git-spark analyze --output report.json

                p.mb-0.
                  Get honest, transparent insights into your repository's activity patterns
                  in seconds. No hidden algorithms, no subjective scores‚Äîjust the facts.

            .row.g-4.mb-4
              .col-md-6
                .card.h-100.border-info
                  .card-body
                    h5.card-title
                      i.bi.bi-book.me-2
                      | Documentation & Examples
                    p.card-text.
                      Comprehensive guides, API documentation, and real-world examples
                      to help you get the most out of git-spark analytics.
                    a.btn.btn-outline-primary.btn-sm(
                      href='https://markhazleton.github.io/git-spark/',
                      target='_blank',
                      rel='noopener noreferrer',
                      aria-label='View git-spark documentation'
                    )
                      i.bi.bi-arrow-right-circle.me-2
                      | View Documentation

              .col-md-6
                .card.h-100.border-info
                  .card-body
                    h5.card-title
                      i.bi.bi-github.me-2
                      | Open Source on GitHub
                    p.card-text.
                      Built in the open with community contributions welcome.
                      Star the repo, report issues, or contribute improvements!
                    a.btn.btn-outline-dark.btn-sm(
                      href='https://github.com/MarkHazleton/git-spark',
                      target='_blank',
                      rel='noopener noreferrer',
                      aria-label='View git-spark on GitHub'
                    )
                      i.bi.bi-github.me-2
                      | View on GitHub

            .alert.alert-success.d-flex.align-items-start
              i.bi.bi-lightbulb-fill.fs-4.me-3.mt-1
              div
                h5.alert-heading.mb-2 Built with the Lessons from This Article
                p.mb-0.
                  Every design decision in git-spark reflects the hard-learned lessons about
                  Git analytics discussed in this article. It's a tool that admits its limitations
                  and empowers you to interpret the data in your unique context. This is what
                  honest engineering metrics should look like.

          section#conclusion.mb-5
            h2.h3.mb-4.text-primary.d-flex.align-items-center
              i.bi.bi-check-circle.me-2
              | Conclusion: From Simple Answers to Better Questions

            p.lead.mb-4.
              The goal isn't to score productivity‚Äîit's to understand it. Great Git analysis
              raises better questions, exposes risk, and improves team dynamics.

            p.mb-4.
              Tools like Git Spark differentiate by being transparent. They refuse to infer
              what they can't know, instead:

            ul.mb-4
              li.mb-2 Reporting only what Git actually contains
              li.mb-2 Avoiding evaluative labels like "excellent"
              li.mb-2 Empowering users to interpret the data themselves

            p.mb-4.
              Instead of asking, <em>"Are we productive?"</em>, ask,
              <em>"Are we set up to succeed?"</em>

            pre.language-javascript
              code.language-javascript.
                console.warn("Deployment status not available from Git");

            .text-center.mt-5
              a.btn.btn-primary.btn-lg(href='/contact', role='button', aria-label='Get in touch to discuss engineering metrics')
                i.bi.bi-bar-chart-fill.me-2
                | Talk Metrics

